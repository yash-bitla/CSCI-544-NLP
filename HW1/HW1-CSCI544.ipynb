{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\YASH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import gzip\n",
    "import contractions\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For preparing the data, I am using the gzip package to open and read the dataset. The datasets consists of 15 columns of which I am extracting the 'review_body' and 'rating' column for this assignment. The dataframe 'df_review_rating' holds these extracted columns. I am converting the 'ratings' to a standard format which I am then using to create our binary classes. For simplicity, I have created a copy of the 'df_review_rating' called 'binary_df' which has an extra column called as 'classes'. This columns holds the labels for our dataset. Finally, I extracted 50000 reviews randomly from each class and stored it in the 'dataset_df' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'amazon_reviews_us_Office_Products_v1_00.tsv.gz'\n",
    "with gzip.open(dataset_path, 'rt', encoding='utf-8') as file:\n",
    "    df = pd.read_csv(file, sep='\\t', on_bad_lines='skip', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marketplace' 'customer_id' 'review_id' 'product_id' 'product_parent'\n",
      " 'product_title' 'product_category' 'star_rating' 'helpful_votes'\n",
      " 'total_votes' 'vine' 'verified_purchase' 'review_headline' 'review_body'\n",
      " 'review_date']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>43081963</td>\n",
       "      <td>R18RVCKGH1SSI9</td>\n",
       "      <td>B001BM2MAC</td>\n",
       "      <td>307809868</td>\n",
       "      <td>Scotch Cushion Wrap 7961, 12 Inches x 100 Feet</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>10951564</td>\n",
       "      <td>R3L4L6LW1PUOFY</td>\n",
       "      <td>B00DZYEXPQ</td>\n",
       "      <td>75004341</td>\n",
       "      <td>Dust-Off Compressed Gas Duster, Pack of 4</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Phffffffft, Phfffffft. Lots of air, and it's C...</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>21143145</td>\n",
       "      <td>R2J8AWXWTDX2TF</td>\n",
       "      <td>B00RTMUHDW</td>\n",
       "      <td>529689027</td>\n",
       "      <td>Amram Tagger Standard Tag Attaching Tagging Gu...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>but I am sure I will like it.</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>52782374</td>\n",
       "      <td>R1PR37BR7G3M6A</td>\n",
       "      <td>B00D7H8XB6</td>\n",
       "      <td>868449945</td>\n",
       "      <td>AmazonBasics 12-Sheet High-Security Micro-Cut ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and the shredder was dirty and the bin was par...</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>24045652</td>\n",
       "      <td>R3BDDDZMZBZDPU</td>\n",
       "      <td>B001XCWP34</td>\n",
       "      <td>33521401</td>\n",
       "      <td>Derwent Colored Pencils, Inktense Ink Pencils,...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     43081963  R18RVCKGH1SSI9  B001BM2MAC       307809868   \n",
       "1          US     10951564  R3L4L6LW1PUOFY  B00DZYEXPQ        75004341   \n",
       "2          US     21143145  R2J8AWXWTDX2TF  B00RTMUHDW       529689027   \n",
       "3          US     52782374  R1PR37BR7G3M6A  B00D7H8XB6       868449945   \n",
       "4          US     24045652  R3BDDDZMZBZDPU  B001XCWP34        33521401   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0     Scotch Cushion Wrap 7961, 12 Inches x 100 Feet  Office Products   \n",
       "1          Dust-Off Compressed Gas Duster, Pack of 4  Office Products   \n",
       "2  Amram Tagger Standard Tag Attaching Tagging Gu...  Office Products   \n",
       "3  AmazonBasics 12-Sheet High-Security Micro-Cut ...  Office Products   \n",
       "4  Derwent Colored Pencils, Inktense Ink Pencils,...  Office Products   \n",
       "\n",
       "  star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0           5            0.0          0.0    N                 Y   \n",
       "1           5            0.0          1.0    N                 Y   \n",
       "2           5            0.0          0.0    N                 Y   \n",
       "3           1            2.0          3.0    N                 Y   \n",
       "4           4            0.0          0.0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                         Five Stars   \n",
       "1  Phffffffft, Phfffffft. Lots of air, and it's C...   \n",
       "2                      but I am sure I will like it.   \n",
       "3  and the shredder was dirty and the bin was par...   \n",
       "4                                         Four Stars   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                                     Great product.  2015-08-31  \n",
       "1  What's to say about this commodity item except...  2015-08-31  \n",
       "2    Haven't used yet, but I am sure I will like it.  2015-08-31  \n",
       "3  Although this was labeled as &#34;new&#34; the...  2015-08-31  \n",
       "4                    Gorgeous colors and easy to use  2015-08-31  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>4</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>4</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>5</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>5</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640254 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating                                        review_body\n",
       "0                 5                                     Great product.\n",
       "1                 5  What's to say about this commodity item except...\n",
       "2                 5    Haven't used yet, but I am sure I will like it.\n",
       "3                 1  Although this was labeled as &#34;new&#34; the...\n",
       "4                 4                    Gorgeous colors and easy to use\n",
       "...             ...                                                ...\n",
       "2640249           4  I can't live anymore whithout my Palm III. But...\n",
       "2640250           4  Although the Palm Pilot is thin and compact it...\n",
       "2640251           4  This book had a lot of great content without b...\n",
       "2640252           5  I am teaching a course in Excel and am using t...\n",
       "2640253           5  A very comprehensive layout of exactly how Vis...\n",
       "\n",
       "[2640254 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_rating = df[['star_rating','review_body']]\n",
    "df_review_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YASH\\AppData\\Local\\Temp\\ipykernel_23768\\2485622692.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_rating['star_rating']=pd.to_numeric(df_review_rating['star_rating'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                        review_body\n",
       "0          5.0                                     Great product.\n",
       "1          5.0  What's to say about this commodity item except...\n",
       "2          5.0    Haven't used yet, but I am sure I will like it.\n",
       "3          1.0  Although this was labeled as &#34;new&#34; the...\n",
       "4          4.0                    Gorgeous colors and easy to use"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_rating['star_rating']=pd.to_numeric(df_review_rating['star_rating'], errors='coerce')\n",
    "df_review_rating = df_review_rating[pd.notna(df_review_rating['star_rating'])]\n",
    "\n",
    "df_review_rating.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We form two classes and select 50000 reviews randomly from each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 1., 4., 2., 3.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_rating['star_rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_df = df_review_rating.copy()\n",
    "\n",
    "def category(row):\n",
    "    if row['star_rating'] == 1 or row['star_rating'] == '1' or row['star_rating'] == 2 or row['star_rating'] == '2' or row['star_rating'] == 3 or row['star_rating'] == '3':\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>4.0</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640237 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  class\n",
       "0                5.0                                     Great product.      2\n",
       "1                5.0  What's to say about this commodity item except...      2\n",
       "2                5.0    Haven't used yet, but I am sure I will like it.      2\n",
       "3                1.0  Although this was labeled as &#34;new&#34; the...      1\n",
       "4                4.0                    Gorgeous colors and easy to use      2\n",
       "...              ...                                                ...    ...\n",
       "2640249          4.0  I can't live anymore whithout my Palm III. But...      2\n",
       "2640250          4.0  Although the Palm Pilot is thin and compact it...      2\n",
       "2640251          4.0  This book had a lot of great content without b...      2\n",
       "2640252          5.0  I am teaching a course in Excel and am using t...      2\n",
       "2640253          5.0  A very comprehensive layout of exactly how Vis...      2\n",
       "\n",
       "[2640237 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df['class'] = df.apply(lambda row: category(row), axis=1)\n",
    "binary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2001183\n",
       "1     639054\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>it says right in the specifications that it wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>These things were horrible.  Used 6 to hang a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Not sure why, but works for one Epson printer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I ordered two letter organizers and received t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>This kit comes with 5 gears, 4 of which go int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I BUY THIS EVERY YEAR.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Good shredder at a good price.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>5.0</td>\n",
       "      <td>We have actually had this system for almost 5 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Awesome!! Work and print just like the origina...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>5.0</td>\n",
       "      <td>works well.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       star_rating                                        review_body  class\n",
       "0              1.0  it says right in the specifications that it wo...      1\n",
       "1              1.0  These things were horrible.  Used 6 to hang a ...      1\n",
       "2              2.0  Not sure why, but works for one Epson printer ...      1\n",
       "3              1.0  I ordered two letter organizers and received t...      1\n",
       "4              3.0  This kit comes with 5 gears, 4 of which go int...      1\n",
       "...            ...                                                ...    ...\n",
       "99995          5.0                             I BUY THIS EVERY YEAR.      2\n",
       "99996          5.0                     Good shredder at a good price.      2\n",
       "99997          5.0  We have actually had this system for almost 5 ...      2\n",
       "99998          5.0  Awesome!! Work and print just like the origina...      2\n",
       "99999          5.0                                        works well.      2\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading rows belonging to classes 1 and 2\n",
    "class1_df = binary_df[binary_df['class'] == 1]\n",
    "class2_df = binary_df[binary_df['class'] == 2]\n",
    "\n",
    "# Randomly choosing 50,000 reviews of each class\n",
    "random_class1_df = class1_df.sample(n = 50000, random_state=42)\n",
    "random_class2_df = class2_df.sample(n = 50000, random_state=42)\n",
    "\n",
    "# Combining the two classes to create a single dataset\n",
    "dataset_df = pd.concat([random_class1_df, random_class2_df])\n",
    "\n",
    "# Reset the indexes\n",
    "dataset_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50000\n",
       "2    50000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['class'].astype(int)\n",
    "dataset_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following tasks were performed for cleaning the dataset - \n",
    "#### 1) Firstly, I looked for rows with missed values and replaced it with an empty string.\n",
    "#### 2) Converted all the reviews to lowercase using the lower() function.\n",
    "#### 3) Removed punctuations from the review by using the string.punctuation package.\n",
    "#### 4) Removed any kind of non-alphabetical characters from the reviews by tokenizing the words and checking if each character is between A-Z or a-z.\n",
    "#### 5) Removed all HTML tags and URLs from the reviews.\n",
    "#### 6) Removed any use of emojis in the reviews.\n",
    "#### 7) Finally, removed all the extra spaces from the reviews.\n",
    "\n",
    "#### I performed contractions on the reviews as well. However, I got slightly better results when contractions was avoided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing empty reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "star_rating    0\n",
      "review_body    1\n",
      "class          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset_df.isnull().values.any())\n",
    "print(dataset_df.isnull().sum())\n",
    "\n",
    "dataset_df = dataset_df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing average length of the reviews in terms of character length in your dataset before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   before\n",
      "0     174\n",
      "1     335\n",
      "2     109\n",
      "3     355\n",
      "4     427\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reviewLen = pd.DataFrame()\n",
    "reviewLen['before'] = dataset_df['review_body'].str.len()\n",
    "print(reviewLen.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting reviews into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   star_rating                                        review_body  class\n",
      "0          1.0  it says right in the specifications that it wo...      1\n",
      "1          1.0  these things were horrible.  used 6 to hang a ...      1\n",
      "2          2.0  not sure why, but works for one epson printer ...      1\n",
      "3          1.0  i ordered two letter organizers and received t...      1\n",
      "4          3.0  this kit comes with 5 gears, 4 of which go int...      1\n"
     ]
    }
   ],
   "source": [
    "dataset_df['review_body'] = dataset_df['review_body'].str.lower()\n",
    "reviewLen['lowercase'] = dataset_df['review_body'].str.len()\n",
    "print(dataset_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   star_rating                                        review_body  class\n",
      "0          1.0  it says right in the specifications that it wo...      1\n",
      "1          1.0  these things were horrible  used 6 to hang a s...      1\n",
      "2          2.0  not sure why but works for one epson printer b...      1\n",
      "3          1.0  i ordered two letter organizers and received t...      1\n",
      "4          3.0  this kit comes with 5 gears 4 of which go into...      1\n"
     ]
    }
   ],
   "source": [
    "def remove_punctuations(text):\n",
    "    if isinstance(text, str): \n",
    "        return ''.join(char for char in text if char not in string.punctuation)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "dataset_df['review_body'] = dataset_df['review_body'].apply(remove_punctuations)\n",
    "reviewLen['punctations'] = dataset_df['review_body'].str.len()\n",
    "\n",
    "print(dataset_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   star_rating                                        review_body  class\n",
      "0          1.0  it says right in the specifications that it wo...      1\n",
      "1          1.0  these things were horrible  used   to hang a s...      1\n",
      "2          2.0  not sure why but works for one epson printer b...      1\n",
      "3          1.0  i ordered two letter organizers and received t...      1\n",
      "4          3.0  this kit comes with   gears   of which go into...      1\n"
     ]
    }
   ],
   "source": [
    "def remove_non_alphabetical(text):\n",
    "    if isinstance(text, str): \n",
    "        return re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "dataset_df['review_body'] = dataset_df['review_body'].apply(remove_non_alphabetical)\n",
    "reviewLen['non_alphanum'] = dataset_df['review_body'].str.len()\n",
    "\n",
    "print(dataset_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   star_rating                                        review_body  class\n",
      "0          1.0  it says right in the specifications that it wo...      1\n",
      "1          1.0  these things were horrible  used   to hang a s...      1\n",
      "2          2.0  not sure why but works for one epson printer b...      1\n",
      "3          1.0  i ordered two letter organizers and received t...      1\n",
      "4          3.0  this kit comes with   gears   of which go into...      1\n"
     ]
    }
   ],
   "source": [
    "dataset_df['review_body'] = dataset_df['review_body'].astype(str)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    try:\n",
    "        clean_text = re.sub(r'<.*?>', '', text)\n",
    "        return clean_text\n",
    "    except TypeError:\n",
    "        return text\n",
    "\n",
    "def remove_urls(text):\n",
    "    try:\n",
    "        clean_text = re.sub(r'http\\S+', '', text)\n",
    "        return clean_text\n",
    "    except TypeError:\n",
    "        return text\n",
    "\n",
    "dataset_df['review_body'] = dataset_df['review_body'].apply(remove_html_tags)\n",
    "dataset_df['review_body'] = dataset_df['review_body'].apply(remove_urls)\n",
    "\n",
    "reviewLen['HTML_URLs'] = dataset_df['review_body'].str.len()\n",
    "\n",
    "print(dataset_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   star_rating                                        review_body  class\n",
      "0          1.0  it says right in the specifications that it wo...      1\n",
      "1          1.0  these things were horrible  used   to hang a s...      1\n",
      "2          2.0  not sure why but works for one epson printer b...      1\n",
      "3          1.0  i ordered two letter organizers and received t...      1\n",
      "4          3.0  this kit comes with   gears   of which go into...      1\n"
     ]
    }
   ],
   "source": [
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "dataset_df['review_body'] = dataset_df['review_body'].apply(remove_emojis)\n",
    "reviewLen['Emojis'] = dataset_df['review_body'].str.len()\n",
    "\n",
    "print(dataset_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   star_rating                                        review_body  class\n",
      "0          1.0  it says right in the specifications that it wo...      1\n",
      "1          1.0  these things were horrible  used   to hang a s...      1\n",
      "2          2.0  not sure why but works for one epson printer b...      1\n",
      "3          1.0  i ordered two letter organizers and received t...      1\n",
      "4          3.0  this kit comes with   gears   of which go into...      1\n"
     ]
    }
   ],
   "source": [
    "dataset_df['review_body'] = dataset_df['review_body'].str.replace(r'\\s+', ' ', regex=False)\n",
    "reviewLen['extraSpaces'] = dataset_df['review_body'].str.len()\n",
    "\n",
    "print(dataset_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contractions on the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expand_contractions(text):\n",
    "#     return contractions.fix(text)\n",
    "\n",
    "# dataset_df['review_body'] = dataset_df['review_body'].apply(expand_contractions)\n",
    "# reviewLen['contractions'] = dataset_df['review_body'].str.len()\n",
    "\n",
    "# print(dataset_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average length of the reviews in terms of character length in your dataset before and after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length of the reviews before clearning -  316.02996\n",
      "The average length of the reviews after cleaning -  304.46909\n"
     ]
    }
   ],
   "source": [
    "reviewLen['after'] = dataset_df['review_body'].str.len()\n",
    "\n",
    "print(\"The average length of the reviews before clearning - \",reviewLen['before'].mean())\n",
    "print(\"The average length of the reviews after cleaning - \", reviewLen['after'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using NLKT package to remove stopwords from the reviews and perform lemmatization on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   star_rating                                        review_body  class\n",
      "0          1.0  says right specifications works iphone lifepro...      1\n",
      "1          1.0  things horrible used hang small unframed canva...      1\n",
      "2          2.0      sure works one epson printer supposed use ink      1\n",
      "3          1.0  ordered two letter organizers received promptl...      1\n",
      "4          3.0  kit comes gears go printer big tan one goes fu...      1\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "dataset_df['review_body'] = dataset_df['review_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "\n",
    "print(dataset_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   star_rating                                        review_body  class\n",
      "0          1.0  say right specification work iphone lifeproof ...      1\n",
      "1          1.0  thing horrible used hang small unframed canvas...      1\n",
      "2          2.0       sure work one epson printer supposed use ink      1\n",
      "3          1.0  ordered two letter organizer received promptly...      1\n",
      "4          3.0  kit come gear go printer big tan one go fuser ...      1\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "dataset_df['review_body'] = dataset_df['review_body'].apply(lemmatize_text)\n",
    "reviewLen['lemmatization'] = dataset_df['review_body'].str.len()\n",
    "\n",
    "print(dataset_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length of the reviews after cleaning -  304.46909\n",
      "The average length of the reviews in terms of character length after preprocessing -  190.75987\n"
     ]
    }
   ],
   "source": [
    "print(\"The average length of the reviews after cleaning - \", reviewLen['after'].mean())\n",
    "print(\"The average length of the reviews in terms of character length after preprocessing - \", reviewLen['lemmatization'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using sklearn to divide our dataset into train and test and finally perform TF-IDF and BOW feature extraction on the training and testing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and BoW Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80000,)\n",
      "X_test shape: (20000,)\n",
      "y_train shape: (80000,)\n",
      "y_test shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(dataset_df['review_body'], dataset_df['class'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", Xtrain.shape)\n",
    "print(\"X_test shape:\", Xtest.shape)\n",
    "print(\"y_train shape:\", Ytrain.shape)\n",
    "print(\"y_test shape:\", Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "Xtrain_tf_idf = tf_idf.fit_transform(Xtrain)\n",
    "Xtest_tf_idf = tf_idf.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowVectorizer = CountVectorizer()\n",
    "Xtrain_BOW = bowVectorizer.fit_transform(Xtrain)\n",
    "Xtest_BOW = bowVectorizer.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(Ytest, pred):\n",
    "    precision = precision_score(Ytest, pred)\n",
    "    recall = recall_score(Ytest, pred)\n",
    "    f1 = f1_score(Ytest, pred)\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'alpha': [0.1, 0.01, 0.001, 0.0001],\n",
    "#     'max_iter': [100, 200, 300, 500, 1000, 5000, 10000],\n",
    "#     'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "# }\n",
    "\n",
    "# # Create the Perceptron model\n",
    "# perceptron = Perceptron(early_stopping=True)\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(perceptron, param_grid, cv=5, scoring='accuracy')\n",
    "# grid_search.fit(Xtrain_tf_idf, Ytrain)\n",
    "\n",
    "# # Get the best model and hyperparameters\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# # Evaluate the best model on the test set\n",
    "# test_accuracy = best_model.score(Xtest_tf_idf, Ytest)\n",
    "\n",
    "# # Print the results\n",
    "# print(f\"Best Hyperparameters: {best_params}\")\n",
    "# print(f\"Cross-Validation Accuracy: {best_score:.4f}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Using Both Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Perceptron model\n",
    "model_perceptron = Perceptron(alpha=0.001, max_iter=1000)\n",
    "\n",
    "model_perceptron = model_perceptron.fit(Xtrain_tf_idf, Ytrain)\n",
    "predPerceptron = model_perceptron.predict(Xtest_tf_idf)\n",
    "\n",
    "precision_tfidf, recall_tfidf, f1_tfidf = get_stats(Ytest, predPerceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Perceptron model\n",
    "model_perceptron = Perceptron(tol=1e-03)\n",
    "\n",
    "model_perceptron = model_perceptron.fit(Xtrain_BOW, Ytrain)\n",
    "predPerceptron = model_perceptron.predict(Xtest_BOW)\n",
    "\n",
    "precision_bow, recall_bow, f1_bow = get_stats(Ytest, predPerceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF FOR PERCEPTRON - 0.7814747339150446, 0.8121574489287494, 0.7965207193119624\n",
      "BOW FOR PERCEPTRON - 0.7933797577029477, 0.8287992027902342, 0.8107027975436204\n"
     ]
    }
   ],
   "source": [
    "print(f\"TF-IDF FOR PERCEPTRON - {precision_tfidf}, {recall_tfidf}, {f1_tfidf}\")\n",
    "print(f\"BOW FOR PERCEPTRON - {precision_bow}, {recall_bow}, {f1_bow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Using Both Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = LinearSVC(C=0.35,\n",
    "    tol=0.001,\n",
    "    max_iter=1000,                 #Total iterations\n",
    "    random_state=16,                #Control the random number generation to control the shuffling\n",
    "    penalty='l1',                  #Norm of Penalty \n",
    "    class_weight=\"balanced\",       #Provides the weight to each class\n",
    "    loss='squared_hinge',          #Specifies the Loss Function\n",
    "    dual=False\n",
    ")\n",
    "\n",
    "model_svm = model_svm.fit(Xtrain_tf_idf , Ytrain)\n",
    "predSVM = model_svm.predict(Xtest_tf_idf)\n",
    "\n",
    "precision_tfidf, recall_tfidf, f1_tfidf = get_stats(Ytest, predSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = LinearSVC(C=0.35,\n",
    "    tol=0.001,\n",
    "    max_iter=1000,                 #Total iterations\n",
    "    random_state=16,                #Control the random number generation to control the shuffling\n",
    "    penalty='l1',                  #Norm of Penalty \n",
    "    class_weight=\"balanced\",       #Provides the weight to each class\n",
    "    loss='squared_hinge',          #Specifies the Loss Function\n",
    "    dual=False\n",
    ")\n",
    "\n",
    "model_svm = model_svm.fit(Xtrain_BOW , Ytrain)\n",
    "predSVM = model_svm.predict(Xtest_BOW)\n",
    "\n",
    "precision_bow, recall_bow, f1_bow = get_stats(Ytest, predSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF FOR SVM - 0.8469055374592834, 0.8550074738415545, 0.8509372210651592\n",
      "BOW FOR SVM - 0.8604989604989605, 0.8249128051818635, 0.8423301958789113\n"
     ]
    }
   ],
   "source": [
    "print(f\"TF-IDF FOR SVM - {precision_tfidf}, {recall_tfidf}, {f1_tfidf}\")\n",
    "print(f\"BOW FOR SVM - {precision_bow}, {recall_bow}, {f1_bow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Using Both Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression(max_iter=10000)\n",
    "\n",
    "model_LR = model_LR.fit(Xtrain_tf_idf , Ytrain)\n",
    "predLR = model_LR.predict(Xtest_tf_idf)\n",
    "\n",
    "precision_tfidf, recall_tfidf, f1_tfidf = get_stats(Ytest, predLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression(max_iter=10000)\n",
    "\n",
    "model_LR = model_LR.fit(Xtrain_BOW , Ytrain)\n",
    "predLR = model_LR.predict(Xtest_BOW)\n",
    "\n",
    "precision_bow, recall_bow, f1_bow = get_stats(Ytest, predLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF FOR Logistic Regression - 0.8460023631350926, 0.856203288490284, 0.8510722599177852\n",
      "BOW FOR Logistic Regression - 0.8583461736004109, 0.8326856003986048, 0.8453211937278705\n"
     ]
    }
   ],
   "source": [
    "print(f\"TF-IDF FOR Logistic Regression - {precision_tfidf}, {recall_tfidf}, {f1_tfidf}\")\n",
    "print(f\"BOW FOR Logistic Regression - {precision_bow}, {recall_bow}, {f1_bow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Using Both Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NB = MultinomialNB(alpha=1)\n",
    "\n",
    "model_NB = model_NB.fit(Xtrain_tf_idf , Ytrain)\n",
    "predNB = model_NB.predict(Xtest_tf_idf)\n",
    "\n",
    "precision_tfidf, recall_tfidf, f1_tfidf = get_stats(Ytest, predNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NB = MultinomialNB(alpha=1)\n",
    "\n",
    "model_NB = model_NB.fit(Xtrain_BOW , Ytrain)\n",
    "predNB = model_NB.predict(Xtest_BOW)\n",
    "\n",
    "precision_bow, recall_bow, f1_bow = get_stats(Ytest, predNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF FOR Naive Bayes - 0.8062212198101683, 0.8549078226208271, 0.8298510350164441\n",
      "BOW FOR Naive Bayes - 0.8342844836868741, 0.7720976581963129, 0.8019873719076701\n"
     ]
    }
   ],
   "source": [
    "print(f\"TF-IDF FOR Naive Bayes - {precision_tfidf}, {recall_tfidf}, {f1_tfidf}\")\n",
    "print(f\"BOW FOR Naive Bayes - {precision_bow}, {recall_bow}, {f1_bow}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
